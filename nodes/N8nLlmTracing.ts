import { BaseCallbackHandler } from '@langchain/core/callbacks/base';
import type { ISupplyDataFunctions } from 'n8n-workflow';
import type { Serialized } from '@langchain/core/load/serializable';

export class N8nLlmTracing extends BaseCallbackHandler {
	name = 'N8nLlmTracing';
	private context: ISupplyDataFunctions;

	constructor(context: ISupplyDataFunctions) {
		super();
		this.context = context;
	}

	async handleLLMStart(
		llm: Serialized,
		prompts: string[],
		runId: string,
		parentRunId?: string,
		extraParams?: Record<string, unknown>,
		tags?: string[],
		metadata?: Record<string, unknown>,
		runName?: string,
	): Promise<void> {
		// æ˜¾ç¤ºLLMå¼€å§‹çŠ¶æ€
		const modelName = llm.id?.[llm.id.length - 1] || 'ModelScope LLM';
		const promptText = prompts.join('\n');
		
		this.context.logger.info(`ğŸš€ ModelScope LLM å¼€å§‹å¤„ç†è¯·æ±‚`, {
			model: modelName,
			runId,
			promptLength: promptText.length,
			prompt: promptText.substring(0, 200) + (promptText.length > 200 ? '...' : ''),
		});

		// åœ¨n8nç•Œé¢æ˜¾ç¤ºçŠ¶æ€
		this.context.sendMessageToUI(`ğŸš€ æ­£åœ¨è°ƒç”¨ ${modelName} å¤„ç†è¯·æ±‚...`);
	}

	async handleLLMEnd(
		output: any,
		runId: string,
		parentRunId?: string,
		tags?: string[],
	): Promise<void> {
		// æ˜¾ç¤ºLLMå®ŒæˆçŠ¶æ€å’Œè¾“å‡º
		let responseText = '';
		
		// å¤„ç†ä¸åŒç±»å‹çš„è¾“å‡ºæ ¼å¼
		if (typeof output === 'string') {
			responseText = output;
		} else if (output?.generations?.[0]?.[0]?.text) {
			responseText = output.generations[0][0].text;
		} else if (output?.content) {
			responseText = output.content;
		} else if (output?.text) {
			responseText = output.text;
		} else {
			responseText = JSON.stringify(output, null, 2);
		}

		this.context.logger.info(`âœ… ModelScope LLM è¯·æ±‚å®Œæˆ`, {
			runId,
			responseLength: responseText.length,
			response: responseText.substring(0, 500) + (responseText.length > 500 ? '...' : ''),
		});

		// åœ¨n8nç•Œé¢æ˜¾ç¤ºå®ŒæˆçŠ¶æ€å’Œéƒ¨åˆ†è¾“å‡º
		const previewText = responseText.substring(0, 200) + (responseText.length > 200 ? '...' : '');
		this.context.sendMessageToUI(`âœ… ModelScope LLM å“åº”å®Œæˆ\nğŸ“ è¾“å‡ºé¢„è§ˆ: ${previewText}`);
	}

	async handleLLMError(
		err: Error,
		runId: string,
		parentRunId?: string,
		tags?: string[],
	): Promise<void> {
		// æ˜¾ç¤ºLLMé”™è¯¯çŠ¶æ€
		this.context.logger.error(`âŒ ModelScope LLM è¯·æ±‚å¤±è´¥`, {
			runId,
			error: err.message,
			stack: err.stack,
		});

		// åœ¨n8nç•Œé¢æ˜¾ç¤ºé”™è¯¯çŠ¶æ€
		this.context.sendMessageToUI(`âŒ ModelScope LLM è¯·æ±‚å¤±è´¥: ${err.message}`);
	}
}